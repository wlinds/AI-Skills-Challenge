{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a training script as a command job in Azure Machine Learning\n",
    "\n",
    "A common challenge when developing machine learning models is to prepare for production scenarios. When you write code to process data and train models, you want the code to be scalable, repeatable, and ready for automation.\n",
    "\n",
    "Though notebooks are ideal for experimentation and development, scripts are a better fit for production workloads. In Azure Machine Learning, you can run a script as a command job. When you submit a command job, you can configure various parameters like the input data and the compute environment. Azure Machine Learning also helps you track your work when working with command jobs to make it easier to compare workloads.\n",
    "\n",
    "You'll learn how to run a script as a command job using the Python software development kit (SDK) v2 for Azure Machine Learning.\n",
    "\n",
    "In this module, you'll learn how to:\n",
    "- Convert a notebook to a script.\n",
    "- Test scripts in a terminal.\n",
    "- Run a script as a command job.\n",
    "- Use parameters in a command job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert a notebook to a script\n",
    "When you've used notebooks for experimentation and development, you'll first need to convert a notebook to a script. Alternatively, you might choose to skip using notebooks and work only with scripts. Either way, there are some recommendations when creating scripts to have production-ready code.\n",
    "\n",
    "Scripts are ideal for testing and automation in your production environment. To create a production-ready script, you'll need to:\n",
    "- Remove nonessential code.\n",
    "- Refactor your code into functions.\n",
    "- Test your script in the terminal.\n",
    "\n",
    "## Remove all nonessential code\n",
    "The main benefit of using notebooks is being able to quickly explore your data. For example, you can use print() and df.describe() statements to explore your data and variables. When you create a script that will be used for automation, you want to avoid including code written for exploratory purposes.\n",
    "\n",
    "The first thing you therefore need to do to convert your code to production code is to remove the nonessential code. Especially when you'll run the code regularly, you want to avoid executing anything nonessential to reduce cost and compute time.\n",
    "\n",
    "## Refactor your code into functions\n",
    "When using code in business processes, you want the code to be easy to read so that anyone can maintain it. One common approach to make code easier to read and test is to use functions.\n",
    "\n",
    "For example, you might have used the following example code in a notebook to read and split the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and visualize the data\n",
    "print(\"Reading data...\")\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "df.head()\n",
    "\n",
    "# split data\n",
    "print(\"Splitting data...\")\n",
    "X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As functions also allow you to test parts of your code, you might prefer to create multiple smaller functions, rather than one large function. If you want to test a part of your code, you can choose to only test a small part and avoid running more code than necessary.\n",
    "\n",
    "You can refactor the code shown in the example into two functions:\n",
    "- Read the data\n",
    "- Split the data\n",
    "\n",
    "An example of refactored code might be the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(csv_file):\n",
    "    # read data\n",
    "    df = get_data(csv_file)\n",
    "\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = split_data(df)\n",
    "\n",
    "# function that reads the data\n",
    "def get_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# function that splits the data\n",
    "def split_data(df):\n",
    "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
    "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">You may have noticed that nonessential code was also omitted in the refactored code. You may choose to use print statements in production code if you'll review the script's output and you want to ensure all code ran as expected. However, when you know you're not going to review the output of a script in a terminal, it's best to remove any code that has no purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your script\n",
    "\n",
    "Before using scripts in production environments, for example by integrating them with automation pipelines, you'll want to test whether the scripts work as expected.\n",
    "\n",
    "One simple way to test your script, is to run the script in a terminal. Within the Azure Machine Learning workspace, you can quickly run a script in the terminal of the compute instance.\n",
    "\n",
    "When you open a script in the Notebooks page of the Azure Machine Learning studio, you can choose to save and run the script in the terminal.\n",
    "\n",
    "Alternatively, you can navigate directly to the terminal of the compute instance. Navigate to the Compute page and select the Terminal of the compute instance you want to use. You can use the following command to run a Python script named train.py:\n",
    "\n",
    "```bash\n",
    "python train.py\n",
    "```\n",
    "\n",
    "Outputs of print statements will show in the terminal. Any possible errors will also appear in the terminal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a script as a command job\n",
    "When you have a script that train a machine learning model, you can run it as a command job in Azure Machine Learning.\n",
    "\n",
    "## Configure and submit a command job\n",
    "To run a script as a command job, you'll need to configure and submit the job.\n",
    "\n",
    "To configure a command job with the Python SDK (v2), you'll use the command function. To run a script, you'll need to specify values for the following parameters:\n",
    "- code: The folder that includes the script to run.\n",
    "- command: Specifies which file to run.\n",
    "- environment: The necessary packages to be installed on the compute before running the command.\n",
    "- compute: The compute to use to run the command.\n",
    "- display_name: The name of the individual job.\n",
    "- experiment_name: The name of the experiment the job belongs to.\n",
    "\n",
    ">Learn more about [the command function and all possible parameters](https://learn.microsoft.com/en-us/python/api/azure-ai-ml/azure.ai.ml) in the reference documentation for the Python SDK (v2).\n",
    "\n",
    "You can configure a command job to run a file named train.py, on the compute cluster named aml-cluster with the following code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python train.py\",\n",
    "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
    "    compute=\"aml-cluster\",\n",
    "    display_name=\"train-model\",\n",
    "    experiment_name=\"train-classification-model\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When your job is configured, you can submit it, which will initiate the job and run the script:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can monitor and review the job in the Azure Machine Learning studio. All jobs with the same experiment name will be grouped under the same experiment. You can find an individual job using the specified display name.\n",
    "\n",
    "All inputs and outputs of a command job are tracked. You can review which command you specified, which compute was used, and which environment was used to run the script on the specified compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use parameters in a command job\n",
    "You can increase the flexibility of your scripts by using parameters. For example, you might have created a script that trains a machine learning model. You can use the same script to train a model on different datasets, or using various hyperparameter values.\n",
    "\n",
    "## Working with script arguments\n",
    "To use parameters in a script, you must use a library such as argparse to read arguments passed to the script and assign them to variables.\n",
    "For example, the following script reads an arguments named training_data, which specifies the path to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def main(args):\n",
    "    # read data\n",
    "    df = get_data(args.training_data)\n",
    "\n",
    "# function that reads the data\n",
    "def get_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\"--training_data\", dest='training_data',\n",
    "                        type=str)\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # return args\n",
    "    return args\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any parameters you expect should be defined in the script. In the script, you can specify what type of value you expect for each parameter and whether you want to set a default value.\n",
    "\n",
    "## Passing arguments to a script\n",
    "To pass parameter values to a script, you need to provide the argument value in the command.\n",
    "\n",
    "For example, if you would pass a parameter value when running a script in a terminal, you would use the following command:\n",
    "\n",
    "```bash\n",
    "python train.py --training_data diabetes.csv\n",
    "```\n",
    "\n",
    "In the example, diabetes.csv is a local file. Alternatively, you could specify the path to a data asset created in the Azure Machine Learning workspace.\n",
    "Similarly, when you want to pass a parameter value to a script you want to run as a command job, you'll specify the values in the command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python train.py --training_data diabetes.csv\",\n",
    "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
    "    compute=\"aml-cluster\",\n",
    "    display_name=\"train-model\",\n",
    "    experiment_name=\"train-classification-model\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After submitting a command job, you can review the input and output parameters you specified.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
