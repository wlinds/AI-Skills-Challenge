{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Azure Machine Learning workspace resources and assets\n",
    "As a data scientist, you want to focus on training machine learning models. Ideally, you want to work with a service that gives you access to all the necessary infrastructure you need to train and deploy a model. You also want the service to allow you to track any work you do to make your model reproducible and robust.\n",
    "\n",
    "Azure Machine Learning provides a platform for data scientists to train, deploy, and manage their machine learning models on the Microsoft Azure platform. Azure Machine Learning provides a comprehensive set of resources and assets to train and deploy effective machine learning models.\n",
    "\n",
    "To use these resources and assets, you create an Azure Machine Learning workspace resource in your Azure subscription. In the Azure Machine Learning workspace, you can manage data, compute resources, models, endpoints, and other artifacts related to your machine learning workloads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Azure ML Service\n",
    "\n",
    "![alt text](assets/overview-azure-resources.png)\n",
    "\n",
    "To create an Azure Machine Learning service, you'll have to:\n",
    "\n",
    "1. Get access to Azure, for example through the Azure portal.\n",
    "2. Sign in to get access to an Azure subscription.\n",
    "3. Create a resource group within your subscription.\n",
    "4. Create an Azure Machine Learning service to create a workspace. When a workspace is provisioned, Azure will automatically create other Azure resources within the same resource group to support the workspace:\n",
    "6. Azure Storage Account: To store files and notebooks used in the workspace, and to store metadata of jobs and models.\n",
    "7. Azure Key Vault: To securely manage secrets such as authentication keys and credentials used by the workspace.\n",
    "8. Application Insights: To monitor predictive services in the workspace.\n",
    "9. Azure Container Registry: Created when needed to store images for Azure Machine Learning environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a workspace\n",
    "You can create an Azure Machine Learning workspace in any of the following ways:\n",
    "- Use the user interface in the Azure portal to create an Azure Machine Learning service.\n",
    "- Create an Azure Resource Manager (ARM) template. [Learn how to use an ARM template to create a workspace.](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-workspace-template?tabs=azcli%3Fazure-portal%3Dtrue)\n",
    "- Use the Azure Command Line Interface (CLI) with the Azure Machine Learning CLI extension. [Learn how to create the workspace with the CLI v2.](https://learn.microsoft.com/en-us/training/modules/create-azure-machine-learning-resources-cli-v2/)\n",
    "- Use the [Azure Machine Learning Python SDK](https://learn.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py). (`pip install azure-ai-ml`)\n",
    "\n",
    "For example, the following code uses the Python SDK to create a workspace named `mlw-example`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Workspace\n",
    "\n",
    "workspace_name = \"mlw-example\"\n",
    "\n",
    "ws_basic = Workspace(\n",
    "    name=workspace_name,\n",
    "    location=\"eastus\",\n",
    "    display_name=\"Basic workspace-example\",\n",
    "    description=\"This example shows how to create a basic workspace\",\n",
    ")\n",
    "ml_client.workspaces.begin_create(ws_basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the workspace in the Azure portal\n",
    "Creating an Azure Machine Learning workspace will typically take between 5-10 minutes to complete. When your workspace is created, you can select the workspace to view its details.\n",
    "![alt text](assets/workspace-portal.png)\n",
    "\n",
    "From the Overview page of the Azure Machine Learning workspace in the Azure portal, you can launch the Azure Machine Learning studio. The Azure Machine Learning studio is a web portal and provides an easy-to-use interface to create, manage, and use resources and assets in the workspace.\n",
    "\n",
    "From the Azure portal, you can also give others access to the Azure Machine Learning workspace, using the Access control.\n",
    "\n",
    "## Give access to the Azure Machine Learning workspace\n",
    "You can give individual users or teams access to the Azure Machine Learning workspace. Access is granted in Azure using role-based access control (RBAC), which you can configure in the Access control tab of the resource or resource group.\n",
    "\n",
    "In the access control tab, you can manage permissions to restrict what actions certain users or teams can perform. For example, you could create a policy that only allows users in the Azure administrators group to create compute targets and datastores. While users in the data scientists group can create and run jobs to train models, and register models.\n",
    "\n",
    "There are three general built-in roles that you can use across resources and resource groups to assign permissions to other users:\n",
    "\n",
    "- Owner: Gets full access to all resources, and can grant access to others using access control.\n",
    "- Contributor: Gets full access to all resources, but can't grant access to others.\n",
    "- Reader: Can only view the resource, but isn't allowed to make any changes.\n",
    "\n",
    "Additionally, Azure Machine Learning has specific built-in roles you can use:\n",
    "\n",
    "- AzureML Data Scientist: Can perform all actions within the workspace, except for creating or deleting compute resources, or editing the workspace settings.\n",
    "- AzureML Compute Operator: Is allowed to create, change, and manage access the compute resources within a workspace.\n",
    "\n",
    "Finally, if the built-in roles aren't meeting your needs, you can create a custom role to assign permissions to other users.\n",
    "\n",
    "> Learn more about [how to manage access to an Azure ML workspace](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-assign-roles).\n",
    "\n",
    "## Organize your workspaces\n",
    "Initially, you might only work with one workspace. However, when working on large-scale projects, you might choose to use multiple workspaces.\n",
    "\n",
    "You can use workspaces to group machine learning assets based on projects, deployment environments (for example, test and production), teams, or some other organizing principle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Azure Machine Learning resources\n",
    "Resources in Azure Machine Learning refer to the infrastructure you need to run a machine learning workflow. Ideally, you want someone like an administrator to create and manage the resources.\n",
    "\n",
    "The resources in Azure Machine Learning include:\n",
    "- The workspace\n",
    "- Compute resources\n",
    "- Datastores\n",
    "\n",
    "## Create and manage the workspace\n",
    "The workspace is the top-level resource for Azure Machine Learning. Data scientists need access to the workspace to train and track models, and to deploy the models to endpoints.\n",
    "\n",
    "However, you want to be careful with who has full access to the workspace. Next to references to compute resources and datastores, you can find all logs, metrics, outputs, models, and snapshots of your code in the workspace.\n",
    "\n",
    "## Create and manage compute resources\n",
    "One of the most important resources you need when training or deploying a model is compute. There are five types of compute in the Azure Machine Learning workspace:\n",
    "\n",
    "- Compute instances: Similar to a virtual machine in the cloud, managed by the workspace. Ideal to use as a development environment to run (Jupyter) notebooks.\n",
    "- Compute clusters: On-demand clusters of CPU or GPU compute nodes in the cloud, managed by the workspace. Ideal to use for production workloads as they automatically scale to your needs.\n",
    "- Kubernetes clusters: Allows you to create or attach an Azure Kubernetes Service (AKS) cluster. Ideal to deploy trained machine learning models in production scenarios.\n",
    "- Attached computes: Allows you to attach other Azure compute resources to the workspace, like Azure Databricks or Synapse Spark pools.\n",
    "- Serverless compute: A fully managed, on-demand compute you can use for training jobs.\n",
    "\n",
    ">As Azure Machine Learning creates and manages serverless compute for you, it's not listed on the compute page in the studio. Learn more about how to [use serverless compute for model training](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-use-serverless-compute).\n",
    "\n",
    "Though compute is the most important resource when working with machine learning workloads, it can also be the most cost-intensive. Therefore, a best practice is to only allow administrators to create and manage compute resources. Data scientists shouldn't be allowed to edit compute, but only use the available compute to run their workloads.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and manage datastores\n",
    "The workspace doesn't store any data itself. Instead, all data is stored in datastores, which are references to Azure data services. The connection information to a data service that a datastore represents, is stored in the Azure Key Vault.\n",
    "\n",
    "When a workspace is created, an Azure Storage account is created and automatically connected to the workspace. As a result, you have four datastores already added to your workspace:\n",
    "\n",
    "- `workspaceartifactstore`: Connects to the `azureml` container of the Azure Storage account created with the workspace. Used to store compute and experiment logs when running jobs.\n",
    "- `workspaceworkingdirectory`: Connects to the file share of the Azure Storage account created with the workspace used by the Notebooks section of the studio. Whenever you upload files or folders to access from a compute instance, it's uploaded to this file share.\n",
    "- `workspaceblobstore`: Connects to the Blob Storage of the Azure Storage account created with the workspace. Specifically `the azureml-blobstore-...` container. Set as the default datastore, which means that whenever you create a data asset and upload data, it's stored in this container.\n",
    "- `workspacefilestore`: Connects to the file share of the Azure Storage account created with the workspace. Specifically the `azureml-filestore-...` file share.\n",
    "\n",
    "Additionally, you can create datastores to connect to other Azure data services. Most commonly, your datastores will connect to an Azure Storage Account or Azure Data Lake Storage (Gen2) as those data services are most often used in data science projects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Azure Machine Learning \n",
    "\n",
    "As a data scientist, you'll mostly work with assets in the Azure Machine Learning workspace. Assets are created and used at various stages of a project and include:\n",
    "- Models\n",
    "- Environments\n",
    "- Data\n",
    "- Components\n",
    "\n",
    "## Create and manage models\n",
    "The end product of training a model is the model itself. You can train machine learning models with various frameworks, like Scikit-learn or PyTorch. A common way to store such models is to package the model as a Python pickle file (.pkl extension).\n",
    "\n",
    "Alternatively, you can use the open-source platform MLflow to store your model in the MLModel format.\n",
    "\n",
    "> Learn more about [logging workflow artifacts as models using MLflow and the MLModel format](https://learn.microsoft.com/en-us/azure/machine-learning/concept-mlflow-models).\n",
    "\n",
    "Whatever format you choose, binary file(s) will represent the model and any corresponding metadata. To persist those files, you can create or register a model in the workspace.\n",
    "\n",
    "When you create a model in the workspace, you'll specify the name and version. Especially useful when you deploy the registered model, versioning allows you to track the specific model you want to use.\n",
    "\n",
    "## Create and manage environments\n",
    "When you work with cloud compute, it's important to ensure that your code runs on any compute that is available to you. Whether you want to run a script on a compute instance, or a compute cluster, the code should execute successfully.\n",
    "\n",
    "Imagine working in Python or R, using open-source frameworks to train a model, on your local device. If you want to use a library such as Scikit-learn or PyTorch, you'll have to install it on your device.\n",
    "\n",
    "Similarly, when you write code that uses any frameworks or libraries, you'll need to ensure the necessary components are installed on the compute that will execute the code. To list all necessary requirements, you can create environments. When you create an environment, you have to specify the name and version.\n",
    "\n",
    "Environments specify software packages, environment variables, and software settings to run scripts. An environment is stored as an image in the Azure Container Registry created with the workspace when it's used for the first time.\n",
    "\n",
    "Whenever you want to run a script, you can specify the environment that needs to be used by the compute target. The environment will install all necessary requirements on the compute before executing the script, making your code robust and reusable across compute targets.\n",
    "\n",
    "## Create and manage data\n",
    "Whereas datastores contain the connection information to Azure data storage services, data assets refer to a specific file or folder.\n",
    "\n",
    "You can use data assets to easily access data every time, without having to provide authentication every time you want to access it.\n",
    "\n",
    "When you create a data asset in the workspace, you'll specify the path to point to the file or folder, and the name and version.\n",
    "\n",
    "## Create and manage components\n",
    "To train machine learning models, you'll write code. Across projects, there may be code you can reuse. Instead of writing code from scratch, you'll want to reuse snippets of code from other projects.\n",
    "\n",
    "To make it easier to share code, you can create a component in a workspace. To create a component, you have to specify the name, version, code, and environment needed to run the code.\n",
    "\n",
    "You can use components when creating pipelines. A component therefore often represents a step in a pipeline, for example to normalize data, to train a regression model, or to test the trained model on a validation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models in the workspace\n",
    "To train models with the Azure Machine Learning workspace, you have several options:\n",
    "- Use Automated Machine Learning.\n",
    "- Run a Jupyter notebook.\n",
    "- Run a script as a job.\n",
    "\n",
    "# Explore algorithms and hyperparameter values with Automated Machine Learning\n",
    "When you have a training dataset and you're tasked with finding the best performing model, you might want to experiment with various algorithms and hyperparameter values.\n",
    "\n",
    "Manually experimenting with different configurations to train a model might take long. Alternatively, you can use Automated Machine Learning to speed up the process.\n",
    "\n",
    "Automated Machine Learning iterates through algorithms paired with feature selections to find the best performing model for your data.\n",
    "\n",
    "![alt text](assets/automated-machine-learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a notebook\n",
    "When you prefer to develop by running code in notebooks, you can use the built-in notebook feature in the workspace.\n",
    "The Notebooks page in the studio allows you to edit and run Jupyter notebooks.\n",
    "\n",
    "![alt text](assets/notebooks.png)\n",
    "\n",
    "All files you clone or create in the notebooks section are stored in the file share of the Azure Storage account created with the workspace.\n",
    "\n",
    "To run notebooks, you'll use a compute instance as they're ideal for development and work similar to a virtual machine.\n",
    "\n",
    "You can also choose to edit and run notebooks in Visual Studio Code, while still using a compute instance to run the notebooks.\n",
    "\n",
    "## Run a script as a job\n",
    "When you want to prepare your code to be production ready, it's better to use scripts. You can easily automate the execution of script to automate any machine learning workload.\n",
    "\n",
    "You can run a script as a job in Azure Machine Learning. When you submit a job to the workspace, all inputs and outputs will be stored in the workspace.\n",
    "\n",
    "![alt text](assets/job-overview.png)\n",
    "\n",
    "There are different types of jobs depending on how you want to execute a workload:\n",
    "\n",
    "- Command: Execute a single script.\n",
    "- Sweep: Perform hyperparameter tuning when executing a single script.\n",
    "- Pipeline: Run a pipeline consisting of multiple scripts or components.\n",
    "\n",
    ">When you submit a pipeline you created with the designer it will run as a pipeline job. When you submit an Automated Machine Learning experiment, it will also run as a job.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
